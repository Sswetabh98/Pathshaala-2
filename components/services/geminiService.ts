
import { GoogleGenAI, GenerateContentResponse, Chat, GroundingChunk, LiveSession, Type, Modality } from "@google/genai";
import { TestQuestion } from '../types';

// FIX: Strictly follow the guideline to use process.env.API_KEY directly for initialization.
const ai = new GoogleGenAI({ apiKey: process.env.API_KEY });

const handleApiError = (error: any, functionName: string): never => {
    console.error(`Gemini API Error in ${functionName}:`, error);
    const msg = error?.message || "Unknown AI Service Error";
    throw new Error(`AI Service Error (${functionName}): ${msg}. Please check your connection or quota.`);
};

// FIX: Implemented missing summarizeConversation for ChatView.
export const summarizeConversation = async (chatText: string): Promise<string> => {
    try {
        const response = await ai.models.generateContent({
            model: 'gemini-3-flash-preview',
            contents: `Summarize the following chat conversation concisely, highlighting key points and next steps:\n\n${chatText}`,
        });
        return response.text || 'Summary unavailable.';
    } catch (error) {
        handleApiError(error, 'summarizeConversation');
    }
};

// FIX: Implemented missing generateAvatar for SettingsPage.
export const generateAvatar = async (prompt: string): Promise<string> => {
    try {
        const response = await ai.models.generateContent({
            model: 'gemini-2.5-flash-image',
            contents: {
                parts: [{ text: `A clean, professional, and friendly square avatar icon suitable for a student or teacher profile on an educational platform. Description: ${prompt}` }]
            },
            config: {
                imageConfig: {
                    aspectRatio: "1:1"
                }
            }
        });
        
        // Find the image part as per guidelines
        if (response.candidates?.[0]?.content?.parts) {
            for (const part of response.candidates[0].content.parts) {
                if (part.inlineData) {
                    const base64Data = part.inlineData.data;
                    const mimeType = part.inlineData.mimeType;
                    return `data:${mimeType};base64,${base64Data}`;
                }
            }
        }
        throw new Error("No image was generated by the model.");
    } catch (error) {
        handleApiError(error, 'generateAvatar');
    }
};

// FIX: Implemented missing summarizeForSMS for MessageApplicantModal.
export const summarizeForSMS = async (emailBody: string): Promise<string> => {
    try {
        const response = await ai.models.generateContent({
            model: 'gemini-3-flash-preview',
            contents: `Summarize this email content into a short, professional SMS message (max 160 characters). Be direct and concise:\n\n${emailBody}`,
        });
        return response.text?.trim().substring(0, 160) || 'Update from Pathshaala.';
    } catch (error) {
        handleApiError(error, 'summarizeForSMS');
    }
};

// FIX: Implemented missing generateLearningPath for LearningPathGenerator.
export const generateLearningPath = async (goals: string, subjects: string, timeframe: string): Promise<string> => {
    try {
        const prompt = `As an expert educational consultant, generate a comprehensive, personalized learning path for a student.
        Goals: ${goals}
        Subjects: ${subjects}
        Timeframe: ${timeframe}
        
        The plan should include weekly objectives, recommended study methods, and major milestones. Use Markdown for structured output.`;

        const response = await ai.models.generateContent({
            model: 'gemini-3-pro-preview',
            contents: prompt,
        });
        return response.text || 'Failed to generate a learning path.';
    } catch (error) {
        handleApiError(error, 'generateLearningPath');
    }
};

export const generateAnnouncementTitle = async (message: string): Promise<string> => {
    try {
        const prompt = `Generate a concise, professional title (max 5 words) for this announcement:\n"${message}"\nOutput ONLY the title.`;
        const response: GenerateContentResponse = await ai.models.generateContent({
            model: 'gemini-3-flash-preview',
            contents: prompt,
        });
        return response.text?.trim().replace(/["']/g, '') || 'New Announcement';
    } catch (error) {
        handleApiError(error, 'generateAnnouncementTitle');
    }
};

export const generateTestQuestions = async (topic: string, numQuestions: number, questionType: string, difficulty: string): Promise<TestQuestion[]> => {
    try {
        const prompt = `Generate ${numQuestions} ${questionType} questions about "${topic}" at ${difficulty} level. 
        For multiple-choice, provide 4 options. Return valid JSON only.`;

        const response: GenerateContentResponse = await ai.models.generateContent({
            model: 'gemini-3-pro-preview',
            contents: prompt,
            config: {
                responseMimeType: "application/json",
                responseSchema: {
                    type: Type.ARRAY,
                    items: {
                        type: Type.OBJECT,
                        properties: {
                            questionText: { type: Type.STRING },
                            questionType: { type: Type.STRING, enum: ['multiple-choice', 'true-false', 'short-answer'] },
                            options: { type: Type.ARRAY, items: { type: Type.STRING }, nullable: true },
                            correctAnswer: { type: Type.STRING }
                        },
                        required: ['questionText', 'questionType', 'correctAnswer']
                    }
                }
            },
        });
        
        const jsonText = response.text?.trim() || '[]';
        return JSON.parse(jsonText) as TestQuestion[];
    } catch (error) {
        handleApiError(error, 'generateTestQuestions');
    }
};

export const getQuickFeedback = async (question: string, answer: string): Promise<string> => {
    try {
        const prompt = `Critique this student answer briefly:\nQ: ${question}\nA: ${answer}`;
        const response = await ai.models.generateContent({
            model: 'gemini-3-flash-preview',
            contents: prompt,
        });
        return response.text || 'No feedback generated.';
    } catch (error) {
        handleApiError(error, 'getQuickFeedback');
    }
};

export const evaluateAnswer = async (question: string, answer: string): Promise<string> => {
    try {
        const prompt = `Detailed educational evaluation:\nQ: ${question}\nA: ${answer}\nInclude score out of 10.`;
        const response = await ai.models.generateContent({
            model: 'gemini-3-pro-preview',
            contents: prompt,
        });
        return response.text || 'Evaluation failed.';
    } catch (error) {
        handleApiError(error, 'evaluateAnswer');
    }
};

export const getComplexResponse = async (prompt: string): Promise<string> => {
    try {
        const response = await ai.models.generateContent({
            model: 'gemini-3-pro-preview',
            contents: prompt,
            config: { thinkingConfig: { thinkingBudget: 24000 } }
        });
        return response.text || 'No response.';
    } catch (error) {
        handleApiError(error, 'getComplexResponse');
    }
};

export const analyzeVideo = async (videoData: string, mimeType: string, prompt: string): Promise<string> => {
    try {
        const response = await ai.models.generateContent({
            model: 'gemini-3-pro-preview',
            contents: {
                parts: [
                    { inlineData: { data: videoData, mimeType } },
                    { text: prompt }
                ]
            },
        });
        return response.text || 'Video analysis failed.';
    } catch (error) {
        handleApiError(error, 'analyzeVideo');
    }
};

export const createChat = (): Chat => {
    return ai.chats.create({
        model: 'gemini-3-flash-preview',
        config: { systemInstruction: 'Friendly assistant for the Pathshaala platform.' }
    });
};

export const createStudyBuddyChat = (): Chat => {
    return ai.chats.create({
        model: 'gemini-3-pro-preview',
        config: { systemInstruction: "Socratic AI Study Buddy. Ask questions to lead students to answers." }
    });
};

export const getChatbotResponse = async (chat: Chat, message: string): Promise<string> => {
    try {
        const response = await chat.sendMessage({ message });
        return response.text || '...';
    } catch (error) {
        handleApiError(error, 'getChatbotResponse');
    }
};

export const getGroundedResponse = async (query: string): Promise<{ text: string; sources: GroundingChunk[] }> => {
    try {
        const response = await ai.models.generateContent({
            model: 'gemini-3-flash-preview',
            contents: query,
            config: { tools: [{ googleSearch: {} }] },
        });
        return { 
            text: response.text || '', 
            sources: response.candidates?.[0]?.groundingMetadata?.groundingChunks || [] 
        };
    } catch (error) {
        handleApiError(error, 'getGroundedResponse');
    }
};

let liveSession: LiveSession | null = null;
function encode(bytes: Uint8Array): string {
    let binary = '';
    for (let i = 0; i < bytes.byteLength; i++) binary += String.fromCharCode(bytes[i]);
    return btoa(binary);
}

export const transcribeAudio = async (stream: MediaStream, onMessage: (text: string, isFinal: boolean) => void) => {
    if (liveSession) await closeLiveSession();
    const sessionPromise = ai.live.connect({
        model: 'gemini-2.5-flash-native-audio-preview-12-2025',
        // FIX: responseModalities MUST contain exactly one modality: Modality.AUDIO.
        config: { 
            responseModalities: [Modality.AUDIO],
            inputAudioTranscription: {} 
        },
        callbacks: {
            onopen: () => {
                const audioContext = new (window.AudioContext || (window as any).webkitAudioContext)({ sampleRate: 16000 });
                const source = audioContext.createMediaStreamSource(stream);
                const processor = audioContext.createScriptProcessor(4096, 1, 1);
                processor.onaudioprocess = (e) => {
                    const input = e.inputBuffer.getChannelData(0);
                    const int16 = new Int16Array(input.length);
                    for (let i = 0; i < input.length; i++) int16[i] = input[i] * 32768;
                    // CRITICAL: Initiating sendRealtimeInput solely relying on sessionPromise resolves.
                    sessionPromise.then(s => s.sendRealtimeInput({ media: { data: encode(new Uint8Array(int16.buffer)), mimeType: 'audio/pcm;rate=16000' } }));
                };
                source.connect(processor);
                processor.connect(audioContext.destination);
            },
            onmessage: (msg) => {
                // Handle input transcription
                if (msg.serverContent?.inputTranscription) onMessage(msg.serverContent.inputTranscription.text, false);
                if (msg.serverContent?.turnComplete) onMessage('', true);
                
                // GUIDELINE: Always handle the audio output stream if configured for speech, even if just consuming it.
                const base64EncodedAudioString = msg.serverContent?.modelTurn?.parts[0]?.inlineData?.data;
                if (base64EncodedAudioString) {
                    console.debug("Received model audio chunk (transcription mode)");
                }
            },
            onerror: (e) => console.error("Live Session Error:", e),
            onclose: () => console.log('Live session closed'),
        },
    });
    liveSession = await sessionPromise;
};

export const closeLiveSession = async () => {
    if (liveSession) { liveSession.close(); liveSession = null; }
};
